{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify sys.path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from platypus import NSGAII, ProcessPoolEvaluator, MaxTime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import time\n",
    "import random \n",
    "\n",
    "import config.config as config\n",
    "from src.data_processing import read_arff, preprocess_data_classification\n",
    "from src.evaluation import *\n",
    "from src.utils import lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback function to store the solutions from each evaluation\n",
    "def callback_function(algorithm):\n",
    "    solution_eval.append(algorithm.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "DATA_PATH = os.path.join('..', 'data', config.DATASET_NAME)\n",
    "\n",
    "dataset = read_arff(DATA_PATH)\n",
    "\n",
    "# Apply sliding window transformation\n",
    "df_lagged = lags(dataset, config.N_STEPS).iloc[config.N_STEPS:,:].reset_index(drop=True)\n",
    "\n",
    "df_dict = preprocess_data_classification(df_lagged)\n",
    "\n",
    "train_X, train_Y, test_X, test_Y = df_dict['normalized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-surrogate cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problems.Multi_Surrogate_FS_ML_Classification import Multi_Surrogate_FS_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results  \n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-dataset-cv-classification-RF.pickle', 'rb') as f:\n",
    "    train_X_cv_RF, train_Y_cv_RF, test_X_cv_RF, test_Y_cv_RF = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generationsPerRun = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dfSolutionsMultiRF = pd.DataFrame(columns=['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'])\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    # define the problem definition\n",
    "    problem = Multi_Surrogate_FS_ML(nVar=config.N_ATTRIB, nobjs=2, X_cv=train_X_cv_RF, Y_cv=train_Y_cv_RF, \n",
    "                                                 regex=f'../models/{config.DATASET_SAVE_NAME}-surrogate-classification-RF-[0-9]*.pkl')\n",
    "    \n",
    "    # instantiate the optimization algorithm to run in parallel\n",
    "    start_time = time.time()\n",
    "    for seedRun in range(config.N_SEEDS):\n",
    "        print(\"--- Run %s ---\" % seedRun)\n",
    "        random.seed(seedRun)\n",
    "        with ProcessPoolEvaluator(config.N_JOBS) as evaluator:\n",
    "            solution_eval = []\n",
    "            algorithm = NSGAII(problem, population_size=config.POPULATION_SIZE, evaluator=evaluator)\n",
    "            algorithm.run(MaxTime(config.MAX_TIME), callback=callback_function)\n",
    "            \n",
    "            results[str(seedRun)] = algorithm.result\n",
    "            generationsPerRun.append(solution_eval)\n",
    "            \n",
    "        df = train_evaluate_ML(train_X, train_Y, algorithm.result, \n",
    "                                     RandomForestClassifier(random_state=config.SEED_VALUE), seedRun, len(solution_eval), n_splits=3,\n",
    "                                     colNames= ['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'],\n",
    "                                     is_classification=True)\n",
    "        dfSolutionsMultiRF = pd.concat([dfSolutionsMultiRF, df], ignore_index=True)\n",
    "        dfSolutionsMultiRF.drop(['1', '2', '3', '4'], axis=1, inplace=True)\n",
    "        \n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-MS-classification-RF.pickle', 'wb') as f:\n",
    "     pickle.dump([dfSolutionsMultiRF], f)\n",
    "        \n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-generations-MS-classification-RF.pickle', 'wb') as f:\n",
    "     pickle.dump([generationsPerRun], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results  \n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-dataset-cv-classification-SVM.pickle', 'rb') as f:\n",
    "    train_X_cv_SVM, train_Y_cv_SVM, test_X_cv_SVM, test_Y_cv_SVM = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generationsPerRun = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dfSolutionsMultiSVM = pd.DataFrame(columns=['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'])\n",
    "    results = {}\n",
    "    \n",
    "    # define the problem definition\n",
    "    problem = Multi_Surrogate_FS_ML(nVar=config.N_ATTRIB, nobjs=2, X_cv=train_X_cv_SVM, Y_cv=train_Y_cv_SVM, \n",
    "                                                 regex=f'../models/{config.DATASET_SAVE_NAME}-surrogate-classification-SVM-[0-9]*.pkl')\n",
    "    \n",
    "    # instantiate the optimization algorithm to run in parallel\n",
    "    start_time = time.time()\n",
    "    for seedRun in range(config.N_SEEDS):\n",
    "        print(\"--- Run %s ---\" % seedRun)\n",
    "        random.seed(seedRun)\n",
    "        with ProcessPoolEvaluator(config.N_JOBS) as evaluator:\n",
    "            solution_eval = []\n",
    "            algorithm = NSGAII(problem, population_size=config.POPULATION_SIZE, evaluator=evaluator)\n",
    "            algorithm.run(MaxTime(config.MAX_TIME), callback=callback_function)\n",
    "            \n",
    "            results[str(seedRun)] = algorithm.result\n",
    "            generationsPerRun.append(solution_eval)\n",
    "            \n",
    "        df = train_evaluate_ML(train_X, train_Y, algorithm.result, \n",
    "                                     svm.SVC(C=10, kernel='poly', random_state=config.SEED_VALUE), seedRun, len(solution_eval), n_splits=3,\n",
    "                                     colNames=['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'],\n",
    "                                     is_classification=True)\n",
    "        dfSolutionsMultiSVM = pd.concat([dfSolutionsMultiSVM, df], ignore_index=True)\n",
    "        dfSolutionsMultiSVM.drop(['1', '2', '3', '4'], axis=1, inplace=True)\n",
    "        \n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-MS-classification-SVM.pickle', 'wb') as f:\n",
    "     pickle.dump([dfSolutionsMultiSVM], f)\n",
    "        \n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-generations-MS-classification-SVM.pickle', 'wb') as f:\n",
    "     pickle.dump([generationsPerRun], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problems.Wrapper_ML_Classification import Wrapper_ML_Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generationsPerRun = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dfSolutionsMultiRF = pd.DataFrame(columns=['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'])\n",
    "    results = {}\n",
    "    \n",
    "    # define the problem definition\n",
    "    problem = Wrapper_ML_Classification(nVar=config.N_ATTRIB, nobjs=2,\n",
    "                                          train_X=train_X, train_y=train_Y, \n",
    "                                          model=RandomForestClassifier(random_state=config.SEED_VALUE))\n",
    "    \n",
    "    # instantiate the optimization algorithm to run in parallel\n",
    "    start_time = time.time()\n",
    "    for seedRun in range(config.N_SEEDS):\n",
    "        print(\"--- Run %s ---\" % seedRun)\n",
    "        random.seed(seedRun)\n",
    "        with ProcessPoolEvaluator(config.N_JOBS) as evaluator:\n",
    "            solution_eval = []\n",
    "            algorithm = NSGAII(problem, population_size=config.POPULATION_SIZE, evaluator=evaluator)\n",
    "            algorithm.run(MaxTime(config.MAX_TIME), callback=callback_function)\n",
    "            \n",
    "            results[str(seedRun)] = algorithm.result\n",
    "            generationsPerRun.append(solution_eval)\n",
    "            \n",
    "        df = train_evaluate_ML(train_X, train_Y, algorithm.result, \n",
    "                                     RandomForestClassifier(random_state=config.SEED_VALUE), seedRun, len(solution_eval), n_splits=3,\n",
    "                                     colNames=['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'],\n",
    "                                     is_classification=True)\n",
    "        dfSolutionsMultiRF = pd.concat([dfSolutionsMultiRF, df], ignore_index=True)\n",
    "        dfSolutionsMultiRF.drop(['1', '2', '3', '4'], axis=1, inplace=True)\n",
    "        \n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-wrapper-classification-RF.pickle', 'wb') as f:\n",
    "     pickle.dump([dfSolutionsMultiRF], f)\n",
    "        \n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-generations-wrapper-classification-RF.pickle', 'wb') as f:\n",
    "     pickle.dump([generationsPerRun], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generationsPerRun = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dfSolutionsMultiRF = pd.DataFrame(columns=['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'])\n",
    "    results = {}\n",
    "    \n",
    "    # define the problem definition\n",
    "    problem = Wrapper_ML_Classification(nVar=config.N_ATTRIB, nobjs=2,\n",
    "                                          train_X=train_X, train_y=train_Y, \n",
    "                                          model=svm.SVC(C=10, kernel='poly', random_state=config.SEED_VALUE))\n",
    "    \n",
    "    # instantiate the optimization algorithm to run in parallel\n",
    "    start_time = time.time()\n",
    "    for seedRun in range(config.N_SEEDS):\n",
    "        print(\"--- Run %s ---\" % seedRun)\n",
    "        random.seed(seedRun)\n",
    "        with ProcessPoolEvaluator(config.N_JOBS) as evaluator:\n",
    "            solution_eval = []\n",
    "            algorithm = NSGAII(problem, population_size=config.POPULATION_SIZE, evaluator=evaluator)\n",
    "            algorithm.run(MaxTime(config.MAX_TIME), callback=callback_function)\n",
    "            \n",
    "            results[str(seedRun)] = algorithm.result\n",
    "            generationsPerRun.append(solution_eval)\n",
    "            \n",
    "        df = train_evaluate_ML(train_X, train_Y, algorithm.result, \n",
    "                                     svm.SVC(C=10, kernel='poly', random_state=config.SEED_VALUE), seedRun, len(solution_eval), n_splits=3,\n",
    "                                     colNames=['Run', 'Generations', 'ACC MOEA', 'N', \n",
    "                                        'ACC BAL CV', 'AUC CV', '1', \n",
    "                                        'Mean ACC BAL CV', 'Mean AUC CV', '2', \n",
    "                                        'ACC BAL StepsAhead', 'AUC StepsAhead', '3', \n",
    "                                        'Mean ACC BAL StepsAhead', 'Mean AUC StepsAhead', '4', \n",
    "                                        'SelectedAttrib'],\n",
    "                                     is_classification=True)\n",
    "        dfSolutionsMultiSVM = pd.concat([dfSolutionsMultiSVM, df], ignore_index=True)\n",
    "        dfSolutionsMultiSVM.drop(['1', '3'], axis=1, inplace=True)\n",
    "        \n",
    "    print(\"--- %s minutes ---\" % ((time.time() - start_time)/60)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-wrapper-classification-SVM.pickle', 'wb') as f:\n",
    "     pickle.dump([dfSolutionsMultiSVM], f)\n",
    "        \n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-generations-wrapper-classification-RF.pickle', 'wb') as f:\n",
    "     pickle.dump([generationsPerRun], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decission  making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-MS-classification-RF.pickle', 'rb') as f:\n",
    "    dfSolutions_multisurr_RF_WS7 = pickle.load(f)[0]\n",
    "dfSolutions_multisurr_RF_WS7['Approach'] = 'Multi-surrogate RF'\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-MS-classification-SVM.pickle', 'rb') as f:\n",
    "    dfSolutions_multisurr_SVM_WS7 = pickle.load(f)[0]\n",
    "dfSolutions_multisurr_SVM_WS7['Approach'] = 'Multi-surrogate SVM'\n",
    "\n",
    "\n",
    "\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-wrapper-classification-RF.pickle', 'rb') as f:\n",
    "    dfSolutions_wrapper_RF_WS7 = pickle.load(f)[0]\n",
    "dfSolutions_wrapper_RF_WS7['Approach'] = 'Wrapper RF'\n",
    "with open(f'../variables/{config.DATASET_SAVE_NAME}-results-wrapper-classification-SVM.pickle', 'rb') as f:\n",
    "    dfSolutions_wrapper_SVM_WS7 = pickle.load(f)[0]\n",
    "dfSolutions_wrapper_SVM_WS7['Approach'] = 'Wrapper SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfConcat = pd.concat([dfSolutions_multisurr_RF_WS7, dfSolutions_multisurr_SVM_WS7,\n",
    "                      dfSolutions_wrapper_RF_WS7, dfSolutions_wrapper_SVM_WS7], \n",
    "                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfH = calculate_H_CV(dfConcat, config.N_STEPS, is_classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBestModels = dfH.loc[dfH.groupby('Approach')['H CV'].idxmax()].sort_values(by='H CV')\n",
    "dfBestModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best prediction models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHoldOut_list = []  \n",
    "\n",
    "column_names = ['Train ACC BAL', 'Train AUC', '1', 'Train ACC BAL StepsAhead', 'Train AUC StepsAhead', '2',\n",
    "                'Test ACC BAL', 'Test AUC', '3', 'Test ACC BAL StepsAhead', 'Test AUC StepsAhead', '4']\n",
    "\n",
    "for _, row in dfBestModels.iterrows():\n",
    "    if row['Approach'].endswith('RF'):\n",
    "        result = best_models_ML_test(\n",
    "            train_X, train_Y, test_X, test_Y, \n",
    "            row[['Approach', 'Run', 'Generations', 'ACC MOEA', 'N', 'H CV', 'SelectedAttrib']], \n",
    "            RandomForestClassifier(random_state=config.SEED_VALUE), colNames=column_names, is_classification=True\n",
    "        )\n",
    "        dfHoldOut_list.append(result)\n",
    "    elif row['Approach'].endswith('SVM'):\n",
    "        result = best_models_ML_test(\n",
    "            train_X, train_Y, test_X, test_Y, \n",
    "            row[['Approach', 'Run', 'Generations', 'ACC MOEA', 'N', 'H CV', 'SelectedAttrib']], \n",
    "            svm.SVC(C=10, kernel='poly', random_state=config.SEED_VALUE), colNames=column_names, is_classification=True\n",
    "        )\n",
    "        dfHoldOut_list.append(result)\n",
    "\n",
    "dfHoldOut = pd.DataFrame(dfHoldOut_list)\n",
    "dfHoldOut.drop(['1', '2', '3', '4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_train, H_test = calculate_H_train_test(dfHoldOut, config.N_STEPS, is_classification=True)\n",
    "dfHoldOut['H Train'] = H_train\n",
    "dfHoldOut['H Test'] = H_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHoldOut.sort_values(by='H Test', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
